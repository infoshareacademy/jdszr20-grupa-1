{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a10f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline    \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f01677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chat = pd.read_csv('ChatGPT_researched_validation_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817250f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental activists vanish after exposing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ghost of Princess Diana sighted at Kensington ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New study shows mega-dose vitamin D cures canc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scientists predict chocolate will go extinct b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Face masks laced with toxic chemicals to sicke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>George Soros secretly funds migrant caravan to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Japan’s Hayabusa2 probe finds organic molecule...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>High school student discovers new exoplanet du...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>COVID-19 vaccine causes infertility in 70% of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Comet Nishimura’s tail visible as Earth passes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  fake\n",
       "0    Environmental activists vanish after exposing ...     1\n",
       "1    Ghost of Princess Diana sighted at Kensington ...     1\n",
       "2    New study shows mega-dose vitamin D cures canc...     1\n",
       "3    Scientists predict chocolate will go extinct b...     1\n",
       "4    Face masks laced with toxic chemicals to sicke...     1\n",
       "..                                                 ...   ...\n",
       "167  George Soros secretly funds migrant caravan to...     1\n",
       "168  Japan’s Hayabusa2 probe finds organic molecule...     0\n",
       "169  High school student discovers new exoplanet du...     0\n",
       "170  COVID-19 vaccine causes infertility in 70% of ...     1\n",
       "171  Comet Nishimura’s tail visible as Earth passes...     0\n",
       "\n",
       "[172 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff2218",
   "metadata": {},
   "source": [
    "#### U mnie bez poniższej komórki były błędy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa74bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "os.environ[\"USE_TORCH\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305996e",
   "metadata": {},
   "source": [
    "Pobranie transformera i uzyskanie embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "transformer_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "embeddings = transformer_model.encode(df_chat['text'].tolist(), convert_to_tensor=False)\n",
    "\n",
    "print(embeddings.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90695412",
   "metadata": {},
   "source": [
    "Zapisanie pickla zawierającego embeddings oraz odpowiadające im etykiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pack embeddings + labels together\n",
    "data_to_save = {\n",
    "    'embeddings': embeddings,        # numpy array\n",
    "    'fake': df_chat['fake'].values     # numpy array of labels\n",
    "}\n",
    "\n",
    "# Save to pickle\n",
    "with open(\"ChatGPT_researched_200_embeddings_all-mpnet-base-v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7a5f7",
   "metadata": {},
   "source": [
    "### KLOD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fa4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_klod = pd.read_csv('klod_validation2_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd8bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biden announces new climate initiative targeti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scientists discover coffee consumption linked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift spotted wearing mysterious ring s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Researchers find Mediterranean diet reduces he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China's economy shows signs of recovery follow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Government officials make all policy decisions...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Economic systems replaced with bartering using...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Universities offering advanced degrees in prof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Transportation revolution involves commuting b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Medical treatments now administered through ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  fake\n",
       "0    Biden announces new climate initiative targeti...     0\n",
       "1    Scientists discover coffee consumption linked ...     0\n",
       "2    Taylor Swift spotted wearing mysterious ring s...     0\n",
       "3    Researchers find Mediterranean diet reduces he...     0\n",
       "4    China's economy shows signs of recovery follow...     0\n",
       "..                                                 ...   ...\n",
       "213  Government officials make all policy decisions...     1\n",
       "214  Economic systems replaced with bartering using...     1\n",
       "215  Universities offering advanced degrees in prof...     1\n",
       "216  Transportation revolution involves commuting b...     1\n",
       "217  Medical treatments now administered through ca...     1\n",
       "\n",
       "[218 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_klod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853be1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "1    113\n",
       "0    105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_klod['fake'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95448bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 768)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "transformer_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# encode a list of texts into dense embeddings\n",
    "embeddings = transformer_model.encode(df_klod['text'].tolist(), convert_to_tensor=False)\n",
    "\n",
    "print(embeddings.shape)   # e.g. (2, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fa729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pack embeddings + labels together\n",
    "data_to_save = {\n",
    "    'embeddings': embeddings,        # numpy array\n",
    "    'fake': df_klod['fake'].values     # numpy array of labels\n",
    "}\n",
    "\n",
    "# Save to pickle\n",
    "with open(\"KLOD_validation2_200_embeddings_all-mpnet-base-v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
